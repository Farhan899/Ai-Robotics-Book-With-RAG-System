<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-module-4-vla/architecture" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.9.2">
<title data-rh="true">Vision-Language-Action (VLA) Architecture | AI / Spec-Driven Humanoid Robotics</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://your-robotics-book.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" name="twitter:image" content="https://your-robotics-book.example.com/img/docusaurus-social-card.jpg"><meta data-rh="true" property="og:url" content="https://your-robotics-book.example.com/docs/module-4-vla/architecture"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="Vision-Language-Action (VLA) Architecture | AI / Spec-Driven Humanoid Robotics"><meta data-rh="true" name="description" content="Introduction to VLA Architecture"><meta data-rh="true" property="og:description" content="Introduction to VLA Architecture"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://your-robotics-book.example.com/docs/module-4-vla/architecture"><link data-rh="true" rel="alternate" href="https://your-robotics-book.example.com/docs/module-4-vla/architecture" hreflang="en"><link data-rh="true" rel="alternate" href="https://your-robotics-book.example.com/docs/module-4-vla/architecture" hreflang="x-default"><script data-rh="true" type="application/ld+json">{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Vision-Language-Action (VLA) Architecture","item":"https://your-robotics-book.example.com/docs/module-4-vla/architecture"}]}</script><link rel="stylesheet" href="/assets/css/styles.efeec1c5.css">
<script src="/assets/js/runtime~main.0a216cd7.js" defer="defer"></script>
<script src="/assets/js/main.1e23080a.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<svg style="display: none;"><defs>
<symbol id="theme-svg-external-link" viewBox="0 0 24 24"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"/></symbol>
</defs></svg>
<script>!function(){var t=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();document.documentElement.setAttribute("data-theme",t||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light")),document.documentElement.setAttribute("data-theme-choice",t||"system")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><link rel="preload" as="image" href="/img/logo.svg"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="theme-layout-navbar navbar navbar--fixed-top"><div class="navbar__inner"><div class="theme-layout-navbar-left navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.svg" alt="AI Robotics Book Logo" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/logo.svg" alt="AI Robotics Book Logo" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">AI / Spec-Driven Humanoid Robotics</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Book</a></div><div class="theme-layout-navbar-right navbar__items navbar__items--right"><a href="https://github.com/Farhan899/Ai-Robotics-Book" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="system mode" aria-label="Switch between dark and light mode (currently system mode)"><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" aria-hidden="true" class="toggleIcon_g3eP systemToggleIcon_QzmC"><path fill="currentColor" d="m12 21c4.971 0 9-4.029 9-9s-4.029-9-9-9-9 4.029-9 9 4.029 9 9 9zm4.95-13.95c1.313 1.313 2.05 3.093 2.05 4.95s-0.738 3.637-2.05 4.95c-1.313 1.313-3.093 2.05-4.95 2.05v-14c1.857 0 3.637 0.737 4.95 2.05z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="theme-layout-main main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist" href="/docs/intro"><span title="Introduction" class="categoryLinkLabel_W154">Introduction</span></a><button aria-label="Expand sidebar category &#x27;Introduction&#x27;" aria-expanded="false" type="button" class="clean-btn menu__caret"></button></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-1-ros2/"><span title="Module 1: The Robotic Nervous System (ROS 2)" class="categoryLinkLabel_W154">Module 1: The Robotic Nervous System (ROS 2)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-2-digital-twin/"><span title="Module 2: The Digital Twin (Gazebo &amp; Unity)" class="categoryLinkLabel_W154">Module 2: The Digital Twin (Gazebo &amp; Unity)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/module-3-ai-robot-brain/"><span title="Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)" class="categoryLinkLabel_W154">Module 3: The AI-Robot Brain (NVIDIA Isaacâ„¢)</span></a></div></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret menu__link--active" role="button" aria-expanded="true" href="/docs/module-4-vla/"><span title="Module 4: Vision-Language-Action (VLA)" class="categoryLinkLabel_W154">Module 4: Vision-Language-Action (VLA)</span></a></div><ul class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-4-vla/"><span title="Module 4: Vision-Language-Action (VLA)" class="linkLabel_WmDU">Module 4: Vision-Language-Action (VLA)</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/module-4-vla/architecture"><span title="Vision-Language-Action (VLA) Architecture" class="linkLabel_WmDU">Vision-Language-Action (VLA) Architecture</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-4-vla/hands-on"><span title="Hands-On: Vision-Language-Action Implementation" class="linkLabel_WmDU">Hands-On: Vision-Language-Action Implementation</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-4-vla/code-examples"><span title="Code Examples: LLM Integration and ROS 2 Action Mapping" class="linkLabel_WmDU">Code Examples: LLM Integration and ROS 2 Action Mapping</span></a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/module-4-vla/troubleshooting"><span title="Troubleshooting: Vision-Language-Action Integration Issues" class="linkLabel_WmDU">Troubleshooting: Vision-Language-Action Integration Issues</span></a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="categoryLink_byQd menu__link menu__link--sublist menu__link--sublist-caret" role="button" aria-expanded="false" href="/docs/capstone/"><span title="Capstone Project: The Autonomous Humanoid" class="categoryLinkLabel_W154">Capstone Project: The Autonomous Humanoid</span></a></div></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li class="breadcrumbs__item"><span class="breadcrumbs__link">Module 4: Vision-Language-Action (VLA)</span></li><li class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link">Vision-Language-Action (VLA) Architecture</span></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>Vision-Language-Action (VLA) Architecture</h1></header>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="introduction-to-vla-architecture">Introduction to VLA Architecture<a href="#introduction-to-vla-architecture" class="hash-link" aria-label="Direct link to Introduction to VLA Architecture" title="Direct link to Introduction to VLA Architecture" translate="no">â€‹</a></h2>
<p>The Vision-Language-Action (VLA) architecture represents a unified framework for integrating perception, cognition, and action in robotic systems. This architecture enables robots to understand natural language commands, perceive their environment visually, and execute appropriate physical actions in response.</p>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="core-vla-components">Core VLA Components<a href="#core-vla-components" class="hash-link" aria-label="Direct link to Core VLA Components" title="Direct link to Core VLA Components" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="1-vision-processing-module">1. Vision Processing Module<a href="#1-vision-processing-module" class="hash-link" aria-label="Direct link to 1. Vision Processing Module" title="Direct link to 1. Vision Processing Module" translate="no">â€‹</a></h3>
<p>The vision processing module handles visual perception and scene understanding:</p>
<p><strong>Visual Feature Extraction</strong></p>
<ul>
<li class="">Convolutional Neural Networks (CNNs) for object detection and recognition</li>
<li class="">Vision Transformers (ViTs) for scene understanding</li>
<li class="">Depth estimation and 3D reconstruction</li>
<li class="">Visual SLAM for localization and mapping</li>
</ul>
<p><strong>Object Recognition and Tracking</strong></p>
<ul>
<li class="">Real-time object detection using YOLO, SSD, or similar architectures</li>
<li class="">Instance segmentation for precise object boundaries</li>
<li class="">Multi-object tracking across frames</li>
<li class="">3D object pose estimation</li>
</ul>
<p><strong>Scene Understanding</strong></p>
<ul>
<li class="">Semantic segmentation for scene parsing</li>
<li class="">Spatial relationship detection</li>
<li class="">Activity recognition in the environment</li>
<li class="">Context-aware perception</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="2-language-processing-module">2. Language Processing Module<a href="#2-language-processing-module" class="hash-link" aria-label="Direct link to 2. Language Processing Module" title="Direct link to 2. Language Processing Module" translate="no">â€‹</a></h3>
<p>The language processing module handles natural language understanding:</p>
<p><strong>Speech Recognition</strong></p>
<ul>
<li class="">Automatic Speech Recognition (ASR) systems (Whisper, Vosk, etc.)</li>
<li class="">Audio preprocessing and noise reduction</li>
<li class="">Speaker identification and diarization</li>
<li class="">Real-time speech-to-text conversion</li>
</ul>
<p><strong>Natural Language Understanding (NLU)</strong></p>
<ul>
<li class="">Large Language Models (LLMs) for command interpretation</li>
<li class="">Named Entity Recognition (NER) for extracting objects and locations</li>
<li class="">Intent classification for determining action types</li>
<li class="">Dependency parsing for understanding command structure</li>
</ul>
<p><strong>Language Grounding</strong></p>
<ul>
<li class="">Mapping language to visual concepts</li>
<li class="">Spatial language understanding</li>
<li class="">Temporal language processing</li>
<li class="">Context-aware language interpretation</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="3-action-planning-module">3. Action Planning Module<a href="#3-action-planning-module" class="hash-link" aria-label="Direct link to 3. Action Planning Module" title="Direct link to 3. Action Planning Module" translate="no">â€‹</a></h3>
<p>The action planning module bridges language understanding and physical execution:</p>
<p><strong>Task Decomposition</strong></p>
<ul>
<li class="">Breaking complex commands into primitive actions</li>
<li class="">Hierarchical task networks (HTNs) for structured planning</li>
<li class="">Symbolic planning using STRIPS or PDDL</li>
<li class="">Constraint satisfaction for resource management</li>
</ul>
<p><strong>Action Selection</strong></p>
<ul>
<li class="">Mapping language intents to robot capabilities</li>
<li class="">Selection of appropriate ROS actions/services</li>
<li class="">Multi-step plan generation and validation</li>
<li class="">Handling of ambiguous or underspecified commands</li>
</ul>
<p><strong>Execution Monitoring</strong></p>
<ul>
<li class="">Real-time plan execution tracking</li>
<li class="">Failure detection and recovery</li>
<li class="">Human-in-the-loop corrections</li>
<li class="">Plan adaptation based on environmental changes</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="vla-integration-architecture">VLA Integration Architecture<a href="#vla-integration-architecture" class="hash-link" aria-label="Direct link to VLA Integration Architecture" title="Direct link to VLA Integration Architecture" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="sequential-architecture">Sequential Architecture<a href="#sequential-architecture" class="hash-link" aria-label="Direct link to Sequential Architecture" title="Direct link to Sequential Architecture" translate="no">â€‹</a></h3>
<p>In the sequential approach, components process information in a pipeline:</p>
<ol>
<li class="">Vision â†’ Language â†’ Action</li>
<li class="">Each stage processes its input and passes results to the next</li>
<li class="">Simple but may miss cross-modal interactions</li>
<li class="">Good for initial implementations</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="parallel-architecture">Parallel Architecture<a href="#parallel-architecture" class="hash-link" aria-label="Direct link to Parallel Architecture" title="Direct link to Parallel Architecture" translate="no">â€‹</a></h3>
<p>In the parallel approach, components operate simultaneously:</p>
<ol>
<li class="">Vision and language processing happen concurrently</li>
<li class="">Results are fused at decision-making stage</li>
<li class="">Better for real-time applications</li>
<li class="">Requires more computational resources</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="cross-modal-attention-architecture">Cross-Modal Attention Architecture<a href="#cross-modal-attention-architecture" class="hash-link" aria-label="Direct link to Cross-Modal Attention Architecture" title="Direct link to Cross-Modal Attention Architecture" translate="no">â€‹</a></h3>
<p>The most advanced approach uses cross-modal attention:</p>
<ol>
<li class="">Vision and language information is processed with mutual attention</li>
<li class="">Language guides visual attention and vice versa</li>
<li class="">Joint embeddings for vision-language understanding</li>
<li class="">State-of-the-art performance but computationally intensive</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="vla-system-design-patterns">VLA System Design Patterns<a href="#vla-system-design-patterns" class="hash-link" aria-label="Direct link to VLA System Design Patterns" title="Direct link to VLA System Design Patterns" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="modular-design-pattern">Modular Design Pattern<a href="#modular-design-pattern" class="hash-link" aria-label="Direct link to Modular Design Pattern" title="Direct link to Modular Design Pattern" translate="no">â€‹</a></h3>
<p><strong>Components:</strong></p>
<ul>
<li class="">Independent vision, language, and action modules</li>
<li class="">Standardized interfaces between modules</li>
<li class="">Easy to replace or upgrade individual components</li>
<li class="">Clear separation of concerns</li>
</ul>
<p><strong>Implementation:</strong></p>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">Voice Input â†’ ASR â†’ NLU â†’ Task Planner â†’ Action Executor â†’ Robot</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">                    â†•         â†•              â†•</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">              Vision Input â†’ Perception â†’ Scene Graph</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="end-to-end-design-pattern">End-to-End Design Pattern<a href="#end-to-end-design-pattern" class="hash-link" aria-label="Direct link to End-to-End Design Pattern" title="Direct link to End-to-End Design Pattern" translate="no">â€‹</a></h3>
<p><strong>Components:</strong></p>
<ul>
<li class="">Joint training of vision-language-action models</li>
<li class="">Direct mapping from input to action</li>
<li class="">Optimized for specific tasks</li>
<li class="">Less interpretable but potentially more efficient</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="hybrid-design-pattern">Hybrid Design Pattern<a href="#hybrid-design-pattern" class="hash-link" aria-label="Direct link to Hybrid Design Pattern" title="Direct link to Hybrid Design Pattern" translate="no">â€‹</a></h3>
<p><strong>Components:</strong></p>
<ul>
<li class="">Combines modular and end-to-end approaches</li>
<li class="">Critical components (safety, ethics) remain modular</li>
<li class="">Performance-critical paths may be end-to-end</li>
<li class="">Balances interpretability and performance</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="ros-2-integration-architecture">ROS 2 Integration Architecture<a href="#ros-2-integration-architecture" class="hash-link" aria-label="Direct link to ROS 2 Integration Architecture" title="Direct link to ROS 2 Integration Architecture" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="vla-node-structure">VLA Node Structure<a href="#vla-node-structure" class="hash-link" aria-label="Direct link to VLA Node Structure" title="Direct link to VLA Node Structure" translate="no">â€‹</a></h3>
<div class="language-text codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_QJqH"><pre tabindex="0" class="prism-code language-text codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">VLA System</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”œâ”€â”€ Speech Recognition Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â”œâ”€â”€ Audio Input</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â”œâ”€â”€ ASR Processing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â””â”€â”€ Text Output</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”œâ”€â”€ Language Understanding Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â”œâ”€â”€ Command Parsing</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â”œâ”€â”€ Intent Classification</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â””â”€â”€ Entity Extraction</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”œâ”€â”€ Vision Processing Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â”œâ”€â”€ Object Detection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â”œâ”€â”€ Scene Understanding</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â””â”€â”€ Spatial Reasoning</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”œâ”€â”€ Task Planning Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â”œâ”€â”€ Plan Generation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â”œâ”€â”€ Constraint Checking</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â”‚   â””â”€â”€ Plan Validation</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">â””â”€â”€ Action Execution Node</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    â”œâ”€â”€ Action Selection</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    â”œâ”€â”€ Execution Monitoring</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">    â””â”€â”€ Feedback Processing</span><br></span></code></pre></div></div>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="communication-patterns">Communication Patterns<a href="#communication-patterns" class="hash-link" aria-label="Direct link to Communication Patterns" title="Direct link to Communication Patterns" translate="no">â€‹</a></h3>
<p><strong>Topic-Based Communication:</strong></p>
<ul>
<li class=""><code>voice_commands</code> - Raw audio or recognized text</li>
<li class=""><code>parsed_commands</code> - Structured command representations</li>
<li class=""><code>scene_description</code> - Environmental information</li>
<li class=""><code>execution_feedback</code> - Action status updates</li>
</ul>
<p><strong>Service-Based Communication:</strong></p>
<ul>
<li class=""><code>parse_command</code> - Request command parsing</li>
<li class=""><code>plan_task</code> - Request task planning</li>
<li class=""><code>validate_action</code> - Request action validation</li>
</ul>
<p><strong>Action-Based Communication:</strong></p>
<ul>
<li class=""><code>execute_plan</code> - Execute multi-step plans with feedback</li>
<li class=""><code>navigate_to</code> - Navigation with goal and feedback</li>
<li class=""><code>manipulate_object</code> - Object manipulation with progress</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="vla-data-flow">VLA Data Flow<a href="#vla-data-flow" class="hash-link" aria-label="Direct link to VLA Data Flow" title="Direct link to VLA Data Flow" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="input-processing">Input Processing<a href="#input-processing" class="hash-link" aria-label="Direct link to Input Processing" title="Direct link to Input Processing" translate="no">â€‹</a></h3>
<ol>
<li class=""><strong>Audio Input</strong>: Raw audio stream from microphone array</li>
<li class=""><strong>Speech Recognition</strong>: Conversion to text with confidence scores</li>
<li class=""><strong>Command Parsing</strong>: Structured representation of intent</li>
<li class=""><strong>Context Integration</strong>: Combination with visual and environmental context</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="decision-making">Decision Making<a href="#decision-making" class="hash-link" aria-label="Direct link to Decision Making" title="Direct link to Decision Making" translate="no">â€‹</a></h3>
<ol>
<li class=""><strong>Intent Resolution</strong>: Determining specific actions from general commands</li>
<li class=""><strong>Entity Grounding</strong>: Mapping language entities to visual objects</li>
<li class=""><strong>Spatial Reasoning</strong>: Determining locations and relationships</li>
<li class=""><strong>Action Selection</strong>: Choosing appropriate robot actions</li>
</ol>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="execution-flow">Execution Flow<a href="#execution-flow" class="hash-link" aria-label="Direct link to Execution Flow" title="Direct link to Execution Flow" translate="no">â€‹</a></h3>
<ol>
<li class=""><strong>Plan Generation</strong>: Creating executable action sequences</li>
<li class=""><strong>Resource Allocation</strong>: Ensuring robot capabilities match requirements</li>
<li class=""><strong>Action Execution</strong>: Executing actions with monitoring</li>
<li class=""><strong>Feedback Integration</strong>: Updating system state based on results</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="vla-performance-considerations">VLA Performance Considerations<a href="#vla-performance-considerations" class="hash-link" aria-label="Direct link to VLA Performance Considerations" title="Direct link to VLA Performance Considerations" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="latency-optimization">Latency Optimization<a href="#latency-optimization" class="hash-link" aria-label="Direct link to Latency Optimization" title="Direct link to Latency Optimization" translate="no">â€‹</a></h3>
<p><strong>Real-time Requirements:</strong></p>
<ul>
<li class="">Audio processing: &lt;100ms for responsiveness</li>
<li class="">Language understanding: &lt;500ms for natural interaction</li>
<li class="">Action planning: &lt;1000ms for complex tasks</li>
<li class="">Overall response: &lt;2000ms for good user experience</li>
</ul>
<p><strong>Optimization Techniques:</strong></p>
<ul>
<li class="">Model quantization for faster inference</li>
<li class="">Edge computing for reduced latency</li>
<li class="">Asynchronous processing where possible</li>
<li class="">Caching of common command interpretations</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="accuracy-vs-speed-trade-offs">Accuracy vs. Speed Trade-offs<a href="#accuracy-vs-speed-trade-offs" class="hash-link" aria-label="Direct link to Accuracy vs. Speed Trade-offs" title="Direct link to Accuracy vs. Speed Trade-offs" translate="no">â€‹</a></h3>
<p><strong>High Accuracy Path:</strong></p>
<ul>
<li class="">Larger models with better performance</li>
<li class="">More comprehensive planning</li>
<li class="">Higher computational requirements</li>
<li class="">Better for safety-critical applications</li>
</ul>
<p><strong>High Speed Path:</strong></p>
<ul>
<li class="">Smaller, optimized models</li>
<li class="">Simplified planning algorithms</li>
<li class="">Lower computational requirements</li>
<li class="">Better for real-time applications</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="safety-and-ethics-in-vla-systems">Safety and Ethics in VLA Systems<a href="#safety-and-ethics-in-vla-systems" class="hash-link" aria-label="Direct link to Safety and Ethics in VLA Systems" title="Direct link to Safety and Ethics in VLA Systems" translate="no">â€‹</a></h2>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="safety-considerations">Safety Considerations<a href="#safety-considerations" class="hash-link" aria-label="Direct link to Safety Considerations" title="Direct link to Safety Considerations" translate="no">â€‹</a></h3>
<p><strong>Command Validation:</strong></p>
<ul>
<li class="">Verification of command safety before execution</li>
<li class="">Resource availability checking</li>
<li class="">Collision avoidance in action planning</li>
<li class="">Emergency stop capabilities</li>
</ul>
<p><strong>Error Handling:</strong></p>
<ul>
<li class="">Graceful degradation when components fail</li>
<li class="">Human-in-the-loop for ambiguous situations</li>
<li class="">Recovery from execution failures</li>
<li class="">Uncertainty quantification and communication</li>
</ul>
<h3 class="anchor anchorTargetStickyNavbar_Vzrq" id="ethical-considerations">Ethical Considerations<a href="#ethical-considerations" class="hash-link" aria-label="Direct link to Ethical Considerations" title="Direct link to Ethical Considerations" translate="no">â€‹</a></h3>
<p><strong>Privacy:</strong></p>
<ul>
<li class="">Audio data handling and storage</li>
<li class="">Visual data processing and retention</li>
<li class="">Consent for data collection</li>
<li class="">Anonymization of personal information</li>
</ul>
<p><strong>Bias Mitigation:</strong></p>
<ul>
<li class="">Language model bias detection and correction</li>
<li class="">Fair treatment across different user groups</li>
<li class="">Transparent decision-making processes</li>
<li class="">Regular bias auditing</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-takeaways">Key Takeaways<a href="#key-takeaways" class="hash-link" aria-label="Direct link to Key Takeaways" title="Direct link to Key Takeaways" translate="no">â€‹</a></h2>
<ul>
<li class="">VLA architecture integrates vision, language, and action in a unified framework</li>
<li class="">Multiple design patterns exist depending on application requirements</li>
<li class="">ROS 2 provides the communication infrastructure for VLA components</li>
<li class="">Performance optimization requires balancing accuracy and speed</li>
<li class="">Safety and ethics are critical considerations in VLA system design</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="key-concepts">Key Concepts<a href="#key-concepts" class="hash-link" aria-label="Direct link to Key Concepts" title="Direct link to Key Concepts" translate="no">â€‹</a></h2>
<ul>
<li class=""><strong>Cross-Modal Attention</strong>: Mechanism for integrating information across different modalities</li>
<li class=""><strong>Language Grounding</strong>: Connecting language to visual and physical concepts</li>
<li class=""><strong>Task Decomposition</strong>: Breaking complex commands into primitive actions</li>
<li class=""><strong>Action Planning</strong>: Creating executable sequences from high-level commands</li>
<li class=""><strong>Sequential Architecture</strong>: Pipeline-based processing of VLA components</li>
<li class=""><strong>Parallel Architecture</strong>: Concurrent processing of vision and language inputs</li>
<li class=""><strong>End-to-End Learning</strong>: Joint optimization of vision-language-action models</li>
<li class=""><strong>ROS Actions</strong>: Asynchronous goal-oriented communication with feedback</li>
</ul>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="practical-exercises">Practical Exercises<a href="#practical-exercises" class="hash-link" aria-label="Direct link to Practical Exercises" title="Direct link to Practical Exercises" translate="no">â€‹</a></h2>
<ol>
<li class="">Design a VLA system architecture for a specific robot application</li>
<li class="">Implement a modular VLA system with standardized interfaces</li>
<li class="">Compare sequential vs parallel processing approaches</li>
<li class="">Evaluate trade-offs between accuracy and performance in VLA systems</li>
</ol>
<h2 class="anchor anchorTargetStickyNavbar_Vzrq" id="common-failure-modes">Common Failure Modes<a href="#common-failure-modes" class="hash-link" aria-label="Direct link to Common Failure Modes" title="Direct link to Common Failure Modes" translate="no">â€‹</a></h2>
<ul>
<li class=""><strong>Cross-Modal Misalignment</strong>: Vision and language components not properly synchronized</li>
<li class=""><strong>Command Ambiguity</strong>: Natural language commands not clearly resolved to actions</li>
<li class=""><strong>Resource Conflicts</strong>: Multiple VLA components competing for computational resources</li>
<li class=""><strong>Latency Issues</strong>: System responses too slow for natural interaction</li>
<li class=""><strong>Context Confusion</strong>: System failing to maintain environmental context across interactions</li>
<li class=""><strong>Safety Violations</strong>: Actions executed without proper safety validation</li>
</ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col noPrint_WFHX"><a href="https://github.com/Farhan899/Ai-Robotics-Book/edit/main/docs/module-4-vla/architecture.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="docusaurus-mt-lg pagination-nav" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/module-4-vla/"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Module 4: Vision-Language-Action (VLA)</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/module-4-vla/hands-on"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Hands-On: Vision-Language-Action Implementation</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#introduction-to-vla-architecture" class="table-of-contents__link toc-highlight">Introduction to VLA Architecture</a></li><li><a href="#core-vla-components" class="table-of-contents__link toc-highlight">Core VLA Components</a><ul><li><a href="#1-vision-processing-module" class="table-of-contents__link toc-highlight">1. Vision Processing Module</a></li><li><a href="#2-language-processing-module" class="table-of-contents__link toc-highlight">2. Language Processing Module</a></li><li><a href="#3-action-planning-module" class="table-of-contents__link toc-highlight">3. Action Planning Module</a></li></ul></li><li><a href="#vla-integration-architecture" class="table-of-contents__link toc-highlight">VLA Integration Architecture</a><ul><li><a href="#sequential-architecture" class="table-of-contents__link toc-highlight">Sequential Architecture</a></li><li><a href="#parallel-architecture" class="table-of-contents__link toc-highlight">Parallel Architecture</a></li><li><a href="#cross-modal-attention-architecture" class="table-of-contents__link toc-highlight">Cross-Modal Attention Architecture</a></li></ul></li><li><a href="#vla-system-design-patterns" class="table-of-contents__link toc-highlight">VLA System Design Patterns</a><ul><li><a href="#modular-design-pattern" class="table-of-contents__link toc-highlight">Modular Design Pattern</a></li><li><a href="#end-to-end-design-pattern" class="table-of-contents__link toc-highlight">End-to-End Design Pattern</a></li><li><a href="#hybrid-design-pattern" class="table-of-contents__link toc-highlight">Hybrid Design Pattern</a></li></ul></li><li><a href="#ros-2-integration-architecture" class="table-of-contents__link toc-highlight">ROS 2 Integration Architecture</a><ul><li><a href="#vla-node-structure" class="table-of-contents__link toc-highlight">VLA Node Structure</a></li><li><a href="#communication-patterns" class="table-of-contents__link toc-highlight">Communication Patterns</a></li></ul></li><li><a href="#vla-data-flow" class="table-of-contents__link toc-highlight">VLA Data Flow</a><ul><li><a href="#input-processing" class="table-of-contents__link toc-highlight">Input Processing</a></li><li><a href="#decision-making" class="table-of-contents__link toc-highlight">Decision Making</a></li><li><a href="#execution-flow" class="table-of-contents__link toc-highlight">Execution Flow</a></li></ul></li><li><a href="#vla-performance-considerations" class="table-of-contents__link toc-highlight">VLA Performance Considerations</a><ul><li><a href="#latency-optimization" class="table-of-contents__link toc-highlight">Latency Optimization</a></li><li><a href="#accuracy-vs-speed-trade-offs" class="table-of-contents__link toc-highlight">Accuracy vs. Speed Trade-offs</a></li></ul></li><li><a href="#safety-and-ethics-in-vla-systems" class="table-of-contents__link toc-highlight">Safety and Ethics in VLA Systems</a><ul><li><a href="#safety-considerations" class="table-of-contents__link toc-highlight">Safety Considerations</a></li><li><a href="#ethical-considerations" class="table-of-contents__link toc-highlight">Ethical Considerations</a></li></ul></li><li><a href="#key-takeaways" class="table-of-contents__link toc-highlight">Key Takeaways</a></li><li><a href="#key-concepts" class="table-of-contents__link toc-highlight">Key Concepts</a></li><li><a href="#practical-exercises" class="table-of-contents__link toc-highlight">Practical Exercises</a></li><li><a href="#common-failure-modes" class="table-of-contents__link toc-highlight">Common Failure Modes</a></li></ul></div></div></div></div></main></div></div></div><footer class="theme-layout-footer footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Book</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Introduction</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/module-1-ros2">ROS 2 Module</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/module-2-digital-twin">Digital Twin Module</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/module-3-ai-robot-brain">AI Robot Brain Module</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/module-4-vla">VLA Module</a></li><li class="footer__item"><a class="footer__link-item" href="/docs/capstone">Capstone Project</a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">Resources</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://docusaurus.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">Docusaurus<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://docs.ros.org/" target="_blank" rel="noopener noreferrer" class="footer__link-item">ROS 2 Documentation<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li><li class="footer__item"><a href="https://developer.nvidia.com/isaac" target="_blank" rel="noopener noreferrer" class="footer__link-item">NVIDIA Isaac<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div><div class="theme-layout-footer-column col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/Farhan899/Ai-Robotics-Book" target="_blank" rel="noopener noreferrer" class="footer__link-item">GitHub<svg width="13.5" height="13.5" aria-label="(opens in new tab)" class="iconExternalLink_nPIU"><use href="#theme-svg-external-link"></use></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2025 AI Robotics Book Project. Built with Docusaurus.</div></div></div></footer><div class="chat-widget"><button class="chat-toggle-button chat-toggle-button-light">ðŸ’¬</button><style>
        .chat-widget {
          position: fixed;
          bottom: 20px;
          right: 20px;
          z-index: 1000;
        }

        .chat-toggle-button {
          width: 60px;
          height: 60px;
          border-radius: 50%;
          border: none;
          color: white;
          font-size: 24px;
          cursor: pointer;
          box-shadow: 0 4px 8px rgba(0, 0, 0, 0.2);
          display: flex;
          align-items: center;
          justify-content: center;
        }

        .chat-toggle-button-light {
          background-color: #4f8bf9;
        }

        .chat-toggle-button-dark {
          background-color: #2c6eaf;
        }

        .chat-window {
          width: 350px;
          height: 500px;
          max-width: 90vw;
          max-height: 70vh;
          display: flex;
          flex-direction: column;
          border-radius: 8px;
          overflow: hidden;
          box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
          margin-bottom: 15px;
        }

        .chat-window-light {
          background-color: #ffffff;
          border: 1px solid #e0e0e0;
        }

        .chat-window-dark {
          background-color: #242526;
          border: 1px solid #444950;
        }

        .chat-header {
          display: flex;
          justify-content: space-between;
          align-items: center;
          padding: 15px;
        }

        .chat-header-light {
          background-color: #f5f6f7;
          border-bottom: 1px solid #e0e0e0;
        }

        .chat-header-dark {
          background-color: #3a3b3c;
          border-bottom: 1px solid #444950;
        }

        .chat-title {
          font-weight: bold;
          font-size: 16px;
        }

        .chat-close {
          background: none;
          border: none;
          font-size: 24px;
          cursor: pointer;
          color: inherit;
          padding: 0;
          width: 30px;
          height: 30px;
          display: flex;
          align-items: center;
          justify-content: center;
        }

        .chat-messages {
          flex: 1;
          overflow-y: auto;
          padding: 15px;
          display: flex;
          flex-direction: column;
          gap: 10px;
        }

        .message {
          max-width: 80%;
          padding: 10px 12px;
          border-radius: 18px;
          position: relative;
        }

        .message-user-light {
          background-color: #4f8bf9;
          color: white;
          align-self: flex-end;
        }

        .message-user-dark {
          background-color: #0d78ea;
          color: white;
          align-self: flex-end;
        }

        .message-bot-light {
          background-color: #f0f2f5;
          color: #333;
          align-self: flex-start;
        }

        .message-bot-dark {
          background-color: #3a3b3c;
          color: #e4e6eb;
          align-self: flex-start;
        }

        .typing-indicator {
          display: flex;
          align-items: center;
          padding: 5px 0;
        }

        .typing-indicator span {
          height: 8px;
          width: 8px;
          background-color: #999;
          border-radius: 50%;
          display: inline-block;
          margin: 0 2px;
          animation: typing 1.4s infinite ease-in-out;
        }

        .typing-indicator span:nth-child(1) {
          animation-delay: -0.32s;
        }

        .typing-indicator span:nth-child(2) {
          animation-delay: -0.16s;
        }

        @keyframes typing {
          0%, 80%, 100% {
            transform: scale(0.8);
            opacity: 0.5;
          }
          40% {
            transform: scale(1);
            opacity: 1;
          }
        }

        .chat-input-area {
          display: flex;
          padding: 10px;
          border-top: 1px solid;
        }

        .chat-input-area-light {
          border-top-color: #e0e0e0;
          background-color: #ffffff;
        }

        .chat-input-area-dark {
          border-top-color: #444950;
          background-color: #242526;
        }

        .chat-input {
          flex: 1;
          border: 1px solid;
          border-radius: 18px;
          padding: 10px 15px;
          resize: none;
          max-height: 100px;
          margin-right: 10px;
          outline: none;
        }

        .chat-input-light {
          background-color: #fff;
          border-color: #e0e0e0;
          color: #333;
        }

        .chat-input-dark {
          background-color: #3a3b3c;
          border-color: #444950;
          color: #e4e6eb;
        }

        .chat-send-button {
          border: none;
          border-radius: 18px;
          padding: 10px 15px;
          background-color: #4f8bf9;
          color: white;
          cursor: pointer;
          align-self: flex-end;
        }

        .chat-send-button:disabled {
          opacity: 0.5;
          cursor: not-allowed;
        }

        @media (max-width: 480px) {
          .chat-window {
            width: 95vw;
            height: 70vh;
          }
        }
      </style></div></div>
</body>
</html>